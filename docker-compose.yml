version: '3.9'
services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: openwebui
    ports:
      - "5000:8080"     # map to external 5000 (so you avoid default)
    environment:
      - OLLAMA_API_BASE=http://ollama:11434
    depends_on:
      - ollama
    volumes:
      - ./openwebui_data:/app/backend/data
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    restart: unless-stopped

  paddleocr:
    image: thomaskuoch/paddleocr-docker:latest
    container_name: paddleocr
    ports:
      - "8866:8866"
    restart: unless-stopped

  connector:
    image: fastapi-connector:latest
    container_name: connector
    ports:
      - "8000:8000"  # internal API for n8n to call
    environment:
      - OCR_URL=http://paddleocr:8866
      - LLM_API=http://ollama:11434
    depends_on:
      - paddleocr
      - ollama
    volumes:
      - ./connector_data:/app/data  # optional for any persistent data
    restart: unless-stopped

networks:
  default:
    name: ai-net